Libraries
###########################################################################
########
library(psych)
library(corrplot)
library(car)
library(randtests)
library(lmtest)
installed.packages("glmnet")
library(glmnet)
###########################################################################
########
#Import Data
###########################################################################
########
Train$instant<-NULL
Train$casual<-NULL
Train$registered<-NULL
Train$dteday<-NULL
#Numeric variables
###########################################################################
########
#Train$dteday <- as.Date(Train$dteday)
Train<-transform(Train, temp = as.numeric(temp))
Train<-transform(Train, atemp = as.numeric(atemp))
Train<-transform(Train, hum = as.numeric(hum))
Train<-transform(Train, windspeed = as.numeric(windspeed))
Train<-transform(Train, cnt = as.numeric(cnt))
Train<-transform(Train, mnth = as.numeric(mnth))
Train<-transform(Train, hr = as.numeric(hr))
Train<-transform(Train, weekday = as.numeric(weekday))
###########################################################################
########
#Factor variables
###########################################################################
########
Train<-transform(Train, yr = factor(yr))
Train<-transform(Train, season = factor(season))
Train<-transform(Train, holiday = factor(holiday))
Train<-transform(Train, workingday = factor(workingday))
Train<-transform(Train, weathersit = factor(weathersit))
str(Train)
summary(Train)
###########################################################################
########
#Create numeric variable dataset
###########################################################################
########
index <- sapply(Train, class) == "numeric"
bikenum <- Train[,index]
#Create factor variable dataset
###########################################################################
########
index <- sapply(Train, class) == "factor"
bikefact <- Train[,index]
###########################################################################
########
#Visual Analysis for numerical variables
###########################################################################
########
par(mfrow=c(2,5))
for (i in 1:nrow(bikenum))
{
 hist(bikenum[,i],col="Orange", main=names(bikenum)[i])
}
par(mfrow=c(3,2))
n <- nrow(bikefact)
barplot(table(bikefact[,1])/n, main="Seasons", col=c("salmon"), names.arg =
c("Spring","Summer","Fall","Winter"))
barplot(table(bikefact[,2])/n, main="Years", col=c("salmon"), names.arg = c("2011","2012"))
barplot(table(bikefact[,3])/n, main="Holiday", col=c("salmon"), names.arg = c("Yes","No"))
barplot(table(bikefact[,4])/n, main="Working Day", col=c("salmon"), names.arg =
c("Yes","No"))
barplot(table(bikefact[,5])/n, main="Weathersit", col=c("salmon"),args.legend = list(x =
"topright"), legend = c("1:Clear Weather","2:Intermidiate Weather","3:Bad Weather"))
cor(bikefact)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(cor(bikenum), method = "color", col = col(200),
 type = "upper", order = "hclust", number.cex = .7,
 addCoef.col = "black", # Add coefficient of correlation
 tl.col = "black", tl.srt = 90, # Text label color and rotation
 # Combine with significance
 sig.level = 0.05, insig = "blank",
 # hide correlation coefficient on the principal diagonal
 diag = FALSE)
#cnt on each numerical variable
###########################################################################
########
par(mfrow=c(2,5))
for(j in 1:(nrow(bikenum)-1)){
 plot(bikenum[,j], bikenum[,ncol(bikenum)], xlab=names(bikenum)[j],
ylab='cnt',cex.lab=1.5,col="salmon")
 abline(lm(bikenum[,ncol(bikenum)]~bikenum[,j]))
}
plot(bikenum[,2], bikenum[,ncol(bikenum)], xlab=names(bikenum)[4],
ylab='cnt',cex.lab=1.5,col="salmon")
abline(lm(bikenum[,ncol(bikenum)]~bikenum[,2]))
write.csv(bikenum[,2],file="demo")
par(mfrow=c(1,4))
plot(bikenum[,4], bikenum[,ncol(bikenum)], xlab=names(bikenum)[4],
ylab='cnt',cex.lab=1.5,col="salmon")
abline(lm(bikenum[,ncol(bikenum)]~bikenum[,4]))
plot(bikenum[,5], bikenum[,ncol(bikenum)],xlab=names(bikenum)[5],
ylab='cnt',cex.lab=1.5,col="salmon")
abline(lm(bikenum[,ncol(bikenum)]~bikenum[,5]))
plot(bikenum[,6], bikenum[,ncol(bikenum)], xlab=names(bikenum)[6],
ylab='cnt',cex.lab=1.5,col="salmon")
abline(lm(bikenum[,ncol(bikenum)]~bikenum[,6]))
plot(bikenum[,7], bikenum[,ncol(bikenum)], xlab=names(bikenum)[7],
ylab='cnt',cex.lab=1.5,col="salmon")
abline(lm(bikenum[,ncol(bikenum)]~bikenum[,7]))
par(mfrow=c(2,5))
for(j in 1:(nrow(bikenum)-1)){
 boxplot(bikenum[,ncol(bikenum)]~bikenum[,j], xlab=names(bikenum)[j],
ylab='cnt',cex.lab=1.5,col="salmon")
 abline(lm(bikenum[,ncol(bikenum)]~bikenum[,j]),col=2)
}
par(mfrow=c(1,2))
plot(bikenum[,4], bikenum[,ncol(bikenum)], xlab=names(bikenum)[4],
ylab='cnt',cex.lab=1.5,col="salmon")
abline(lm(bikenum[,ncol(bikenum)]~bikenum[,4]))
plot(bikenum[,5], bikenum[,ncol(bikenum)], xlab=names(bikenum)[5],
ylab='cnt',cex.lab=1.5,col="salmon")
abline(lm(bikenum[,ncol(bikenum)]~bikenum[,5]))
###########################################################################
########
#cnt on factor variables
###########################################################################
########
par(mfrow=c(3,2))
for(j in 1:(nrow(bikenum)-1)){
 boxplot(bikenum[,ncol(bikenum)]~bikefact[,j], xlab=names(bikefact)[j],
ylab='cnt',cex.lab=2.0,col="salmon")
 abline(lm(bikenum[,ncol(bikenum)]~bikefact[,j]))
}
#----------------------------------------------------------------------------------
#Initial regression model
#----------------------------------------------------------------------------------
#Model (adj 1)
model <- lm(cnt ~., data = bikenum)
summary(model)
#New model
summary(step(model, direction = "both"))
#Collinearity check
round(vif(model),1)#Using VIF
vif(step(model, direction = "both"))
#Model1
# atemp, windspeed arent significant and we exclude them
model1<- lm(cnt ~.-atemp-windspeed, data = bikenum)
summary(model1)
#Test the significance model1
anova(model1)
#Model2-No intercept
model2<- lm(cnt ~.-1-atemp-windspeed, data = bikenum)
summary(model2)
AIC(model2)
vif(model2)
n <- nrow(bikenum)
true.r2 <- 1-sum(model2$res^2)/((n-1)*var(bikenum$cnt))
true.r2
anova(model1,model2)
#Constant model
#----------------------------------------------------------------------------------
model0 <- lm(cnt ~ 1, data = bikenum)
summary(model0)
anova(model2,model0)
#----------------------------------------------------------------------------------
#Adding factors
#----------------------------------------------------------------------------------
fullmodel<-lm(cnt~., data=Train) #FULL MODEL
summary(fullmodel)
vif(fullmodel)
AIC(fullmodel)
#Model 3
model3<-step(fullmodel, direction = "both")
summary(model3)
vif(model3)
AIC(model3)
###########################################################################
########
#Anova Test
###########################################################################
########
#Now we test whether the additional parameters in two nested models are zero or not
anova(model2,model3)
#----------------------------------------------------------------------------------
#Centralized Model
#----------------------------------------------------------------------------------
bike_Central<- as.data.frame(scale(bikenum, center = TRUE, scale = F))
bike_Central$cnt<-bikenum$cnt
bike_Central<-as.data.frame(c(bike_Central,bikefact))
sapply(bike_Central,mean)
sapply(bike_Central,sd)
central_model<-lm(cnt~.-mnth-atemp-windspeed-holiday-workingday-yr,
data=bike_Central)
summary(central_model)
finalmodel<-model3
Stud.residuals <- rstudent(finalmodel)
yhat <- fitted(finalmodel)
par(mfrow=c(1,3))
plot(finalmodel,col="BLUE", which = 2)
{plot(yhat, Stud.residuals,main="Residuals Variance",col="PINK")
 abline(h=c(-2,2), col=2, lty=2)}
{plot(yhat, Stud.residuals^2,main="Residuals Variance R^2",col="GREEN")
 abline(h=4, col=2, lty=2)}
shapiro.test(finalmodel$df.residual)
ncvTest(finalmodel)
par(mfrow=c(1,3))
yhat.quantiles<-cut(yhat, breaks=quantile(yhat, probs=seq(0,1,0.25)), dig.lab=6)
table(yhat.quantiles)
leveneTest(rstudent(finalmodel)~yhat.quantiles)
boxplot(rstudent(finalmodel)~yhat.quantiles,col="Black",main="Variance in Quantiles")
# -------------------------------
# Check for residuals linearity
# -------------------------------
residualPlot(finalmodel, type='rstudent',col="Yellow",main="Residuals Linearity")
residualPlots(finalmodel, plot=F)
# --------------------------------
# Check for residuals Independence
# --------------------------------
plot(rstudent(finalmodel), type='l',col="pink",main="Residuals Dependence")
runs.test(finalmodel$res)
dwtest(finalmodel)
durbinWatsonTest(finalmodel)
# --------------------------------
# Check for outliers
# --------------------------------
leveragePlots(finalmodel,col="salmon")
par(mfrow=c(2,3))
plot(finalmodel,col="salmon", which = 2)
yhat.quantiles<-cut(yhat, breaks=quantile(yhat, probs=seq(0,1,0.25)), dig.lab=6)
table(yhat.quantiles)
leveneTest(rstudent(finalmodel)~yhat.quantiles)
boxplot(rstudent(finalmodel)~yhat.quantiles,col="salmon",main="Variance in Quantiles")
{plot(yhat, Stud.residuals^2,main="Residuals Variance R^2",col="salmon")
 abline(h=4, col=2, lty=2)}
residualPlot(finalmodel, type='rstudent',col="salmon",main="Residuals Linearity")
residualPlots(finalmodel, plot=F)
plot(rstudent(finalmodel), type='l',col="salmon",main="Residuals Independence")
runs.test(finalmodel$res)
dwtest(finalmodel)
durbinWatsonTest(finalmodel)

