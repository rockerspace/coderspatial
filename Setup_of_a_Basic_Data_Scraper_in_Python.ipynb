{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SSco7p8d5MXZ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://example.com'  # Replace with the URL of the website you want to scrape\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    print('Request successful!')\n",
        "else:\n",
        "    print('Failed to retrieve the webpage')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpLNvUEW5ayC",
        "outputId": "c5c357b5-0566-45ca-9b95-0a73638c23a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Print the title of the webpage to verify\n",
        "print(soup.title.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGh5eRl65ghe",
        "outputId": "02e72d2e-3610-4664-8c9c-3671952d8046"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example Domain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the table containing the data\n",
        "table = soup.find('table', {'id': 'data-table'})  # Replace 'data-table' with the actual id or class of the table\n",
        "\n",
        "# Extract table rows\n",
        "rows = soup.find_all('tr')  # Or another tag\n",
        "container = soup.find('div', class_='something')\n",
        "if container:\n",
        "    for row in container.find_all('p'):\n",
        "        print(row.text)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Loop through the rows and extract data\n",
        "data = []\n",
        "for row in rows:\n",
        "    cols = row.find_all('td')\n",
        "    cols = [col.text.strip() for col in cols]\n",
        "    data.append(cols)\n",
        "\n",
        "# Convert the data into a pandas DataFrame for easier manipulation\n",
        "df = pd.DataFrame(data, columns=['Column1', 'Column2', 'Column3'])  # Replace with actual column names\n",
        "\n",
        "# Display the scraped data\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12u2pNE15lNM",
        "outputId": "294f084c-0af0-45f8-8808-c365e54ca46c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Column1, Column2, Column3]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('scraped_data.csv', index=False)"
      ],
      "metadata": {
        "id": "EfDdeZLW6V28"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Send an HTTP request to the webpage\n",
        "url = 'https://en.wikipedia.org/wiki/Cloud-computing_comparison'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML content\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Print the title of the webpage to verify\n",
        "print(\"Title: \" + soup.title.text)\n",
        "\n",
        "# Find the table containing the data (selecting the first table by default)\n",
        "table = soup.find('table')\n",
        "\n",
        "# Extract table rows\n",
        "rows = table.find_all('tr')\n",
        "\n",
        "# Extract headers from the first row (using <th> tags)\n",
        "headers = [header.text.strip() for header in rows[0].find_all('th')]\n",
        "\n",
        "# Loop through the rows and extract data (skip the first row with headers)\n",
        "data = []\n",
        "for row in rows[1:]:  # Start from the second row onwards\n",
        "    cols = row.find_all('td')\n",
        "    cols = [col.text.strip() for col in cols]\n",
        "    data.append(cols)\n",
        "\n",
        "# Convert the data into a pandas DataFrame, using the extracted headers as column names\n",
        "df = pd.DataFrame(data, columns=headers)\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify\n",
        "print(df.head())\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('scraped_data.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLJCd7kY6ZLc",
        "outputId": "526ad391-75da-4046-fadc-ebd9cb8f3354"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Cloud-computing comparison - Wikipedia\n",
            "                      Provider Launched Block storage Assignable IPs  \\\n",
            "0        Google Cloud Platform     2013           Yes             No   \n",
            "1  Oracle Cloud Infrastructure     2014           Yes            Yes   \n",
            "2          Amazon Web Services     2006           Yes            Yes   \n",
            "3                    IBM Cloud     2005           Yes            Yes   \n",
            "4              Microsoft Azure     2010           Yes            Yes   \n",
            "\n",
            "  SMTP support IOPS Guaranteed minimum Security  \\\n",
            "0        No[1]                     Yes   Yes[2]   \n",
            "1          Yes                     Yes   Yes[5]   \n",
            "2   Partial[6]                     Yes   Yes[7]   \n",
            "3        No[9]                     Yes  Yes[10]   \n",
            "4      Yes[11]                     Yes  Yes[12]   \n",
            "\n",
            "                                           Locations             Notes  \n",
            "0  br, ca, cl, us, be, ch, de, es, fi, it, po, nl...  SMTP blocked.[4]  \n",
            "1  us, ca, br, de, uk, nl, ch, in, aus, jp, kr, saud                    \n",
            "2  us, ca, br, ie, de, uk, cn, sg, au, jp, kr, in...   List of bugs[8]  \n",
            "3  us, gb, fr, de, nl, in, au, hk, kr, it, jp, no...                    \n",
            "4  ca, us, br, ie, nl, de, uk, cn, au, jp, in, kr...  List of bugs[13]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TGuzJmwv6fG5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}